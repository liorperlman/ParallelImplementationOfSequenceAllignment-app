Author: Lior Perlman 203311808

### General Info
***

MPI+OpenMP+CUDA Integration project.
The project runs with 2 processes only.

Initially the array is known to process 0.
It sends half of the positions to process 1.
Both processes start to make the mutant array for half of the positions each using OpenMP.
Half of the mutants and signs arrays generated using OpenMP and half generated using CUDA.
The best mutant details found by process 1 is sended from process 1 to process 0, which perform a test to check if the mutant is better (gets better score) than the best mutant found by process 0.
The mutants are generated by replacing all more than one letter (all letters, according to the second bonus paragraph.
There are still comment laid in order to demonstrate single letter replace if needed)
***

Side information: 
In order to compile the program use: /make
In order to run the program on a single computer use: /make run
In order to run the program on two computers use: /make runOn2
***

Parallelized explanation and complexity evaluation:
Process 0 divide the work by sending half of the positions to process 1 to make.
Each of them use OpenMP by launching as many threads as the number of positions they have to create (which is half of the total positions).
Each thread creating half of the mutant as well as half of the signs array and sending the second half to CUDA to create.
After each mutant and signs array completion by CUDA (which happens on every thread) we compare all the results from all the threads (which represent half of the positions).
After we've found the best mutant on each process, process 1 sends his best mutant details to process 0 which compare between his best mutant details to process' 1 best mutant details and decide the overall best mutant.

The rational of choosing the specific architecture is to generate all the mutants (by different positions) at the same time
so the number of repositions won't factor the runtime.

The use of MPI reduce the run time by half. (each doing half of the positions)
The use of openMP reduce the run time of all positions assigns to a single position. (each thread doing a single position)
The use of cuda reduce the run time of a single position by half. (CUDA does half of the sequence at the time of a single letter)
That's why the total runtime of the program is: (seq2->count/2)~O(m/2)~O(m) [when m represent the size of seq2]
***


